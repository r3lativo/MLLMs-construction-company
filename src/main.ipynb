{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from utils import *\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(model, processor, conversation, target_name, images=None, max_new_tokens=128):\n",
    "    \"\"\"\n",
    "    Generates a response for the given model using the (filtered) conversation history.\n",
    "    \n",
    "    - Filters out system messages that are not intended for the current model.\n",
    "    - role_name should be the current model's identifier (e.g., \"Architect\" or \"Builder\").\n",
    "    \"\"\"\n",
    "\n",
    "    # Filter conversation for the current model.\n",
    "    filtered_conversation = filter_conversation(conversation, target_model=target_name)\n",
    "    \n",
    "    # Build the prompt using the processor's chat template.\n",
    "    prompt = processor.apply_chat_template(filtered_conversation, add_generation_prompt=True)\n",
    "\n",
    "    inputs = processor(\n",
    "        images=images,\n",
    "        text=prompt,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(model.device)\n",
    "    \n",
    "    generate_ids = model.generate(**inputs,\n",
    "                                  do_sample=False,     # Deterministic generation\n",
    "                                  max_new_tokens=max_new_tokens)\n",
    "    output = processor.batch_decode(generate_ids,\n",
    "                                    skip_special_tokens=True,\n",
    "                                    clean_up_tokenization_spaces=False)\n",
    "    \n",
    "    parsed = output[0].split(\"[/INST] \")[-1]\n",
    "\n",
    "    # Since [INST] and [/INST] are NOT single tokens (i.e., they are processede like '['+'/'+'INST'+'])\n",
    "    # the model picks it up and understands that when [/ is happening, there is a switch of role.\n",
    "    # The model then tries to force the switch of role and complete the task on its own (lol).\n",
    "    if \"[/\" in parsed:\n",
    "        #Truncate at the point of the unwanted token\n",
    "        parsed = parsed.split(\"[/\")[0]\n",
    "\n",
    "    # Minimal cleanup to remove special tokens (adjust as needed)\n",
    "    #response_text = output.replace(\"[INST]\", \"\").replace(\"[/INST]\", \"\").strip()\n",
    "    return output, parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_structure(structure_id):\n",
    "    # Where the rendered structures are\n",
    "    gold_processed_path = \"../data/structures/gold-processed\"\n",
    "\n",
    "    # Construct the path to the structure\n",
    "    structure_path = os.path.join(gold_processed_path, structure_id)\n",
    "\n",
    "    # Load the structure JSON\n",
    "    try:\n",
    "        json_path = os.path.join(structure_path, f\"{structure_id}.json\")\n",
    "        s_json = json.load(open(json_path, \"r\"))\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"Structure {structure_id} not found.\")\n",
    "    \n",
    "    s_images_list = []\n",
    "\n",
    "    # Load the images\n",
    "    for filename in os.listdir(structure_path):\n",
    "        # Check if the file has a JPG or JPEG extension (case insensitive)\n",
    "        if filename.lower().endswith(('.jpg', '.jpeg')):\n",
    "            img_path = os.path.join(structure_path, filename)\n",
    "            try:\n",
    "                # Open the image file using PIL\n",
    "                img = Image.open(img_path)\n",
    "                s_images_list.append(img)\n",
    "            except IOError:\n",
    "                raise IOError(f\"Warning: Could not open image {img_path}\")\n",
    "    \n",
    "    return s_json, s_images_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"llava-hf/llava-v1.6-mistral-7b-hf\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "structure_id = \"C1_bell\"\n",
    "max_rounds = 10\n",
    "max_new_tokens = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,  # The compute dtype for 4-bit operations\n",
    "    bnb_4bit_use_double_quant=True,        # Whether to use double quantization (optional)\n",
    "    bnb_4bit_quant_type=\"nf4\"              # The quantization type, e.g. \"nf4\" or \"fp4\"\n",
    "    )\n",
    "\n",
    "# Load Processor and Model from id\n",
    "processor = LlavaNextProcessor.from_pretrained(model_id,\n",
    "                                                #use_fast=True,  # Processor for images\n",
    "                                                padding_side=\"left\")\n",
    "\n",
    "model_A = LlavaNextForConditionalGeneration.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=quantization_config,\n",
    "    torch_dtype=torch.float16,\n",
    "    low_cpu_mem_usage=True,\n",
    ").to(device)\n",
    "\n",
    "model_B = LlavaNextForConditionalGeneration.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=quantization_config,\n",
    "    torch_dtype=torch.float16,\n",
    "    low_cpu_mem_usage=True,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_json, s_images_list = load_structure(structure_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_round = 0\n",
    "conversation_history = setup_roles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "full_outputs = []\n",
    "\n",
    "while current_round < 10:\n",
    "        print(f\"===== Round {current_round + 1} =====\")\n",
    "\n",
    "        # ----- Architect's Turn -----\n",
    "        # For the first turn, pass the images; later turns might not require images.\n",
    "        full_output_A, modelA_response = generate_response(\n",
    "            model=model_A,\n",
    "            processor=processor,\n",
    "            conversation=conversation_history,\n",
    "            target_name=\"Architect\",\n",
    "            images=s_images_list if current_round == 0 else None,\n",
    "            max_new_tokens=max_new_tokens\n",
    "        )\n",
    "        full_outputs.append(full_output_A)\n",
    "        print(f\"[ARCHITECT]\\n {modelA_response}\")\n",
    "\n",
    "        # Append Architect's response to the conversation history.\n",
    "        conversation_history.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": modelA_response}\n",
    "            ]\n",
    "        })\n",
    "\n",
    "        # Check if Architect signaled to finish.\n",
    "        if \"[FINISH]\" in modelA_response:\n",
    "            pprint(\"Finishing conversation as indicated by Architect.\")\n",
    "            break\n",
    "\n",
    "        # ----- Builder's Turn -----\n",
    "        full_output_B, modelB_response = generate_response(\n",
    "            model=model_B,\n",
    "            processor=processor,\n",
    "            conversation=conversation_history,\n",
    "            target_name=\"Builder\",\n",
    "            images=None,\n",
    "            max_new_tokens=max_new_tokens\n",
    "        )\n",
    "        full_outputs.append(full_output_B)\n",
    "        print(f\"[BUILDER]\\n {modelB_response}\")\n",
    "\n",
    "        # Append Builder's response to the conversation history.\n",
    "        conversation_history.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": modelB_response}\n",
    "            ]\n",
    "        })\n",
    "\n",
    "        current_round += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': [({'type': 'image'},\n",
      "               {'type': 'image'},\n",
      "               {'type': 'image'},\n",
      "               {'type': 'image'}),\n",
      "              {'text': 'You are an agent playing a collaborative building task '\n",
      "                       'along with a partner. Your role is that of the '\n",
      "                       'Architect, while your partner is the Builder. You will '\n",
      "                       'be shown images of a target structure built in a voxel '\n",
      "                       'world, images of a target structure built in a voxel '\n",
      "                       'world, and your job is to guide the Builder in order '\n",
      "                       'to replicate it. Give clear and easy to follow '\n",
      "                       'instructions. Proceed step by step and avoid providing '\n",
      "                       'too many instructions all at once. The Builder will '\n",
      "                       'reply with the actions it took and, possibly, '\n",
      "                       \"clarification questions. Acknowledge the Builder's \"\n",
      "                       'actions and feedback in order to understand whether '\n",
      "                       'they are on the right track or not and to help them. '\n",
      "                       'When you think that the Builder correctly completed '\n",
      "                       \"the structure, output '[FINISH]' to trigger the end of \"\n",
      "                       'the game. Here are the images of the target structure '\n",
      "                       'from four points of view: ',\n",
      "               'type': 'text'}],\n",
      "  'role': 'user',\n",
      "  'target': 'Architect'}]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "use_img = True\n",
    "use_json = False\n",
    "\n",
    "img_text = \"images of a target structure built in a voxel world, \"\n",
    "json_text = \"a JSON text file representing the target structure, \"\n",
    "\n",
    "img_dict = {\"type\": \"image\"}\n",
    "json_raw = None\n",
    "\n",
    "arch_content = []\n",
    "if use_img: arch_content.append(img_dict)\n",
    "if use_json: arch_content.append(json_raw)\n",
    "arch_content.append({\n",
    "                \"type\": \"text\",\n",
    "                \"text\":\n",
    "                    (\n",
    "                        \"You are an agent playing a collaborative building task along with a partner. \"\n",
    "                        \"Your role is that of the Architect, while your partner is the Builder. You will be shown \"\n",
    "                        \"images of a target structure built in a voxel world, \"\n",
    "                        f\"{img_text if use_img else ''}{\"and \" if use_img and use_json else ''}{json_text if use_json else ''}\"\n",
    "                        \"and your job is to guide the Builder \"\n",
    "                        \"in order to replicate it. Give clear and easy to follow instructions. Proceed step by step \"\n",
    "                        \"and avoid providing too many instructions all at once. The Builder will reply with the \"\n",
    "                        \"actions it took and, possibly, clarification questions. Acknowledge the Builder's actions \"\n",
    "                        \"and feedback in order to understand whether they are on the right track or not and to help \"\n",
    "                        \"them. When you think that the Builder correctly completed the structure, output '[FINISH]' \"\n",
    "                        \"to trigger the end of the game. Here are the images of the target structure from four points of view: \"\n",
    "                    )\n",
    "            },)\n",
    "\n",
    "# Use the \"target\" field in system messages to restrict visibility.\n",
    "conversation_history = []\n",
    "\n",
    "# System message for Architect (visible only to Architect)\n",
    "conversation_history.append({\n",
    "    \"role\": \"user\",\n",
    "    \"target\": \"Architect\",\n",
    "    \"content\": arch_content\n",
    "})\n",
    "\n",
    "pprint(conversation_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mllm-con",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
