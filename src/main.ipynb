{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/disi/miniconda3/envs/mllm-con/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import argparse\n",
    "from utils import *\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_structure(structure_id):\n",
    "    # Where the rendered structures are\n",
    "    gold_processed_path = \"../data/structures/gold-processed\"\n",
    "\n",
    "    # Construct the path to the structure\n",
    "    structure_path = os.path.join(gold_processed_path, structure_id)\n",
    "\n",
    "    # Load the structure JSON\n",
    "    try:\n",
    "        json_path = os.path.join(structure_path, f\"{structure_id}.json\")\n",
    "        s_json = json.load(open(json_path, \"r\"))\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"Structure {structure_id} not found.\")\n",
    "    \n",
    "    s_images_list = []\n",
    "\n",
    "    # Load the images\n",
    "    for filename in os.listdir(structure_path):\n",
    "        # Check if the file has a JPG or JPEG extension (case insensitive)\n",
    "        if filename.lower().endswith(('.jpg', '.jpeg')):\n",
    "            img_path = os.path.join(structure_path, filename)\n",
    "            try:\n",
    "                # Open the image file using PIL\n",
    "                img = Image.open(img_path)\n",
    "                s_images_list.append(img)\n",
    "            except IOError:\n",
    "                raise IOError(f\"Warning: Could not open image {img_path}\")\n",
    "    \n",
    "    return s_json, s_images_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(model, processor, conversation, role_name, images=None, max_new_tokens=128):\n",
    "    \"\"\"\n",
    "    Generates a response for the given model using the (filtered) conversation history.\n",
    "    \n",
    "    - Filters out system messages that are not intended for the current model.\n",
    "    - role_name should be the current model's identifier (e.g., \"Architect\" or \"Builder\").\n",
    "    \"\"\"\n",
    "\n",
    "    # Filter conversation for the current model.\n",
    "    filtered_conversation = filter_conversation(conversation, target_model=role_name)\n",
    "    \n",
    "    # Build the prompt using the processor's chat template.\n",
    "    prompt = processor.apply_chat_template(filtered_conversation, add_generation_prompt=True)\n",
    "\n",
    "    inputs = processor(\n",
    "        images=images,\n",
    "        text=prompt,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(model.device)\n",
    "    \n",
    "    generate_ids = model.generate(**inputs, max_new_tokens=max_new_tokens)\n",
    "    output = processor.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "    \n",
    "\n",
    "    # Minimal cleanup to remove special tokens (adjust as needed)\n",
    "    #response_text = output.replace(\"[INST]\", \"\").replace(\"[/INST]\", \"\").strip()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"llava-hf/llava-v1.6-mistral-7b-hf\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "structure_id = \"C1_bell\"\n",
    "max_rounds = 10\n",
    "max_new_tokens = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some kwargs in processor config are unused and will not have any effect: num_additional_image_tokens. \n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.08s/it]\n",
      "Some kwargs in processor config are unused and will not have any effect: num_additional_image_tokens. \n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.07it/s]\n"
     ]
    }
   ],
   "source": [
    "model_A, processor_A = initialize_model(model_id, device, 4)\n",
    "model_B, processor_B = initialize_model(model_id, device, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_json, s_images_list = load_structure(structure_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_round = 0\n",
    "conversation_history = setup_roles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'target': 'Architect',\n",
       "  'content': [{'type': 'image'},\n",
       "   {'type': 'image'},\n",
       "   {'type': 'image'},\n",
       "   {'type': 'image'},\n",
       "   {'type': 'text',\n",
       "    'text': \"You are an agent playing a collaborative building task along with a partner. Your role is that of the Architect, while your partner is the Builder. You will be shown images of a target structure built in a voxel world, and your job is to guide the Builder in order to replicate it. Give clear and easy to follow instructions. Proceed step by step and avoid providing too many instructions all at once. The Builder will reply with the actions it took and, possibly, clarification questions. Acknowledge the Builder's actions and feedback in order to understand whether they are on the right track or not and to help them. When you think that the Builder correctly completed the structure, output '[FINISH]' to trigger the end of the game. Here are the images of the target structure from four points of view: \"}]},\n",
       " {'role': 'user',\n",
       "  'target': 'Builder',\n",
       "  'content': [{'type': 'text',\n",
       "    'text': \"You are an agent playing a collaborative building task along with a partner. Your role is that of the Builder, while your partner is the Architect. Your job is to follow the Architect's instructions to build what they describe. Output the corresponding actions in terms of XYZ coordinates, like 'add.(red, 0, 1, 0)' or 'remove.(green, 0, 1, 3)'. If you have any doubts or need clarification, ask the Architect. The Architect will tell you when the structure is complete.\"}]},\n",
       " {'role': 'user', 'content': [{'type': 'text', 'text': '[START]'}]}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    }
   ],
   "source": [
    "modelA_response = generate_response(\n",
    "            model=model_A,\n",
    "            processor=processor_A,\n",
    "            conversation=conversation_history,\n",
    "            role_name=\"Architect\",\n",
    "            images=s_images_list if current_round == 0 else None,\n",
    "            max_new_tokens=max_new_tokens\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"[INST]  \\n \\n \\n \\nYou are an agent playing a collaborative building task along with a partner. Your role is that of the Architect, while your partner is the Builder. You will be shown images of a target structure built in a voxel world, and your job is to guide the Builder in order to replicate it. Give clear and easy to follow instructions. Proceed step by step and avoid providing too many instructions all at once. The Builder will reply with the actions it took and, possibly, clarification questions. Acknowledge the Builder's actions and feedback in order to understand whether they are on the right track or not and to help them. When you think that the Builder correctly completed the structure, output '[FINISH]' to trigger the end of the game. Here are the images of the target structure from four points of view:  [/INST][INST] [START] [/INST] Alright, let's start building the target structure. From the top-down view, it looks like we have a base that is a 3x3 grid. We'll need to build up from there.\\n\\nFor the base, we'll need to place blocks in the following pattern:\\n- The top left corner should be purple.\\n- The top right corner should be green.\\n- The bottom left corner should be gray.\\n- The bottom right corner should be red.\\n\\nOnce you have the base set up, we can start building the structure. Let me know when you have the base set up, and we'll move on to the next step. \"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelA_response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mllm-con",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
